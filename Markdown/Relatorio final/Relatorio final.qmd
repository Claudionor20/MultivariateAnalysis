---
title: "Análise Multivariada"
author: "Caio Falcão, Claudionor Ferreira, Guilherme Ceacero, Paulo Martinez"
toc: true
toc-title: "INDEX"
toc-location: left
format: 
  html:
    theme: default
    toc: true
    html-math-method: katex
    css: styles.css
    toc-location: left
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

Trabalho final da disciplina de Análise Multivariada, referente ao
primeiro período de 2024. Esse trabalho é uma colaboração de Caio
Falcão, Claudionor Ferreira, Guilherme Ceacero e Paulo Martinez.

# Questão 1

<<<<<<< HEAD
Nesta seção, demonstramos a direção discriminante de Fisher para
discriminação linear entre duas populações. Consideramos duas populações
$\pi_1$ e $\pi_2$ baseadas na amostra rotulada
$( {(x_j , \pi_i), \space j = 1, \ldots , n, \space i = 1, 2} )$, em que
$n_1 + n_2 = n$ e $n_i$ é o número de elementos da população $\pi_i$.
=======
Nesta seção, demonstramos a direção discriminante de Fisher para discriminação linear entre duas populações. Consideramos duas populações $\pi_1$ e $\pi_2$ baseadas na amostra rotulada $( {(x_j , \pi_i), \space j = 1, \ldots , n, \space i = 1, 2} )$, em que $n_1 + n_2 = n$ e $n_i$ é o número de elementos da população $\pi_i$.
>>>>>>> 9fcdf72993727f9e2351175e6f4f50192b609315

## Considerações

### Definições

-   $\bar{x}_i$ representa o vetor de médias das observações em $\pi_i$.
-   $S_i$ representa a matriz de covariâncias amostral das observações
    em $\pi\_i$.
-   $S_p$ = $\frac{(n_1-1)S_1 + (n_2-1)S_2}{n-2}$ é a matriz de
    covariâncias combinada.

### Projeção

Para $\alpha, x \in \mathbb{R}^p$, definimos a projeção como:

$$
\begin{align}
 & z = \alpha^T x
\end{align}
$$

E consequentemente, as médias das populações $\pi_1$ e $\pi_2$
projetadas serão

$\hat m_1 = \alpha^T \space \bar{x}_1$

$\hat m_2 = \alpha^T \space \bar{x}_1$

E a diferença dessas projeções sendo

$\hat m_1 - \hat m_2 = \alpha^T(\bar{x}_1 - \bar{x}_2)$.

A variabilidade resultante na projeção é a variância da projeção $z$,
que é dada por

$$
\begin{align}
    & Var(z) = Var(\alpha^T x) \nonumber \\
    & = \alpha^T \space Var(x) \space \alpha \nonumber \\
    & = \alpha^T \mathcal{S}_p \space \alpha \nonumber
\end{align}
$$

E então,
$\phi = \left(\frac{\hat m_1 - \hat m_2}{S_z}\right)^2 = \left(\frac{\alpha^T (\bar{x}_1 - \bar{x}_2)}{\sqrt{\alpha^T S_p \space \alpha}}\right)^2$.

### Maximização da Distância

Queremos encontrar a direção $\alpha$ que maximiza a distância entre as
médias projetadas das populações com relação à variabilidade resultante
na projeção. Ou seja, queremos maximizar:

$$
\begin{equation}
\phi = \left(\frac{\alpha^T (\bar{x}_1 - \bar{x}_2)}{\sqrt{\alpha^T S_p \alpha}}\right)^2
\end{equation}
$$

## Demonstração

Vamos aplicar a restrição $\alpha^T S_p \space \alpha$ constante e igual
à $1$, pois do contrário poderíamos ter $\phi$ tão grande quanto
desejável. Nesse caso, então, vamos usar o método de Lagrange para
otimização com restrição.

Começamos com a expressão a ser maximizada:

$$
\phi = \frac{(\alpha^T (\bar{x}_1 - \bar{x}_2))^2}{\alpha^T S_p \space \alpha}
$$

Para maximizar $\phi$, usamos multiplicadores de Lagrange. Definimos a
função Lagrangiana:

$$ 
\mathcal{L}(\alpha, \lambda) = (\alpha^T (\bar{x}_1 - \bar{x}_2))^2 - \lambda (\alpha^T S_p \space \alpha - 1)
$$

Tomamos a derivada em relação a $\alpha$ e a igualamos a zero:

$$
\frac{\partial \mathcal{L}}{\partial \alpha} = 2 (\bar{x}_1 - \bar{x}_2) (\alpha^T (\bar{x}_1 - \bar{x}_2)) - \lambda 2 S_p \alpha = 0
$$

E agora, para $\lambda$:

$$
\frac{\partial \mathcal{L}}{\partial \lambda} = \alpha^T S_p \space \alpha - 1
$$

O que nos fornece então o seguinte sistema de equações:

$$
\begin{cases}
\frac{\partial \mathcal{L}}{\partial \alpha} = 2 (\bar{x}_1 - \bar{x}_2) (\alpha^T (\bar{x}_1 - \bar{x}_2)) - \lambda 2 S_p \space \alpha = 0 \\
\\
\frac{\partial \mathcal{L}}{\partial \lambda} = \alpha^T S_p \space \alpha - 1
\end{cases}
$$

Da primeira equação, temos que

$$
(\bar{x}_1 - \bar{x}_2) = \lambda S_p \space \alpha
$$

Para encontrar $\lambda$, substituímos $\alpha$ na segunda equação de
restrição:

$$
\begin{equation}
(\bar{x}_1 - \bar{x}_2) = \lambda S_p \space \alpha \implies \alpha = \frac{S_p^{-1}(\bar{x}_1 - \bar{x}_2)}{\lambda}
\end{equation}
$$

A partir da restrição $\alpha^T S_p \space \alpha = 1$, temos:

$$
\begin{align}
 & \left(\frac{S_p^{-1}(\bar{x}_1 - \bar{x}_2)}{\lambda}\right)^T S_p \left(\frac{S_p(\bar{x}_1 - \bar{x}_2)}{\lambda}\right) = 1 \nonumber \\
 & \frac{1}{\lambda^2}(\bar{x}_1 - \bar{x}_2)^T S_p^{-1} \space S_p S_p^{-1} (\bar{x}_1 - \bar{x}_2) = 1 \nonumber \\
 & \lambda^2 = (\bar{x}_1 - \bar{x}_2)^T S_p^{-1} (\bar{x}_1 - \bar{x}_2) \nonumber \\
 & \lambda = \sqrt{(\bar{x}_1 - \bar{x}_2)^T S_p^{-1} (\bar{x}_1 - \bar{x}_2)}
\end{align}
$$

E agora, substituindo $\lambda$ encontrado em (4) na equação de $\alpha$
(3), temos:

$$
\begin{equation}
\alpha = \frac{S_p^{-1}(\bar{x}_1 - \bar{x}_2)}{\sqrt{(\bar{x}_1 - \bar{x}_2)^T S_p^{-1} (\bar{x}_1 - \bar{x}_2)}}
\end{equation}
$$

<<<<<<< HEAD
Note que o denominador dessa equação é um escalar $1\times1$, e portanto, a
direção de $\alpha$ que maximiza a diferença das duas populações é dada
pelo vetor $\alpha = S_p^{-1}(\bar{x}_1 - \bar{x}_2)$ pelo método de
otimização restrita de Lagrange.
=======
Note que o denominador dessa equação é um escalar $1 \times 1$, e portanto, a direção de $\alpha$ que maximiza a diferença das duas populações é dada pelo vetor $\alpha = S_p^{-1}(\bar{x}_1 - \bar{x}_2)$ pelo método de otimização restrita de Lagrange.
>>>>>>> 9fcdf72993727f9e2351175e6f4f50192b609315

## Conclusão

Dessa forma, mostramos que a direção $\alpha$ que maximiza a distância
entre as médias projetadas das populações com relação à variabilidade
resultante na projeção é a direção discriminante de Fisher.

# Questão 2

```{r bibliotecas, warning=FALSE}
library(candisc) #base de dados wolves
library(dplyr)
library(ggplot2)
library(cluster)
library(gridExtra)
library(factoextra)
library(mclust)
library(MVN)
library(flextable)
library(MASS)
library(labelled)
library(tidyr)
```

Após realizar a importação da base de dados, verificamos se a base
possui valores faltantes e se as variáveis estão corretamente
formatadas:

```{r base1, warning=FALSE}
data(Wolves) #base da biblioteca candisc
head(Wolves)
naniar::miss_var_summary(Wolves)
str(Wolves)
```

Com a base devidamente importada e sem a presença de valores faltantes,
prosseguimos com a análise descritiva:

## Análise descritiva:

Primeiro, verificamos as variáveis qualitativas da base de dados:

```{r grupos}
table(Wolves$sex)
table(Wolves$location)

Wolves |> ggplot(aes(x = group))+
  geom_bar(fill = "#5A639C", width = .5)+
  labs(y = "Frequência", x = "Grupo")+
  theme_minimal()
```

Observa-se que o grupo mais presente na amostra são de lobos machos da
localização "ar".

Para as variáveis quantitativas, considere as seguintes medidas de
resumo:

```{r medidas}

rotulos <- function(df) {
  labels <- sapply(df, function(x) attr(x, "label"))
  df[] <- lapply(df, function(x) {
    if (is.labelled(x)) {
      as.numeric(x)
    } else {
      as.numeric(x) # Garantir que as colunas sejam convertidas para numeric
    }
  })
  return(list(data = df, labels = labels))
}

# Função para calcular medidas estatísticas
medidas_resumo <- function(data) {
  result <- rotulos(data)
  data <- result$data
  labels <- result$labels
  
  # Transformar os dados para o formato longo
  data_long <- data %>%
    pivot_longer(everything(), names_to = "variavel", values_to = "value")
  
  # Calcular medidas estatísticas para cada variável
  medidas <- data_long %>%
    group_by(variavel) %>%
    summarise(
      media = mean(value),
      dp = sd(value),
      coef = (mean(value) / sd(value)) * 100,
      mediana = median(value),
      IQQ = paste(quantile(value, 0.25), quantile(value, 0.75), sep = "-"),
      ASS = 3 * (mean(value) - median(value)) / sd(value)
    )
  
  # Adicionar os rótulos como uma nova coluna
  medidas$variavel  <- labels[medidas$variavel]
  
  return(medidas)
}

# Testar a função
medidas_res = medidas_resumo(Wolves[, 4:12])

medidas_res |> 
  flextable() |>  
  theme_vanilla() |>  
  autofit() |> 
  set_caption(caption = "Medidas resumos base Wolves") |> 
  color(j = 1, color = "darkblue") |> # Colorir a coluna das variáveis
   set_header_labels(
    variable = "Variável",
    media = "Média",
    dp = "Desvio Padrão",
    coef = "Cv (%)",
    mediana = "Mediana",
    IQQ = "Intervalo Interquartil",
    ASS = "Assimetria",
    label = "Variável"
  ) |> 
  colformat_double(
  digits = 2
) 
```

Além das medidas resumos, pode ser de interesse realizar uma análise
gráfica nos dados. Para isso, veja o histograma das variáveis:

```{r histograma}
par(mfrow = c(3,3))
str(Wolves)
for(i in 1:ncol(Wolves)){
  name = names(Wolves)[i]
  if(is.numeric(Wolves[[i]])){
    label = attr(Wolves[[i]], "label")
    main_title = ifelse(!is.null(label), label, name)
    
    hist(Wolves[[i]], xlab= "", main = main_title)
  }
}
```

Surge também, a necessidade de verificar a correlação entre as
variáveis.

```{r correlacao}
pairs(Wolves[,4:12], 
      pch=21)

corrplot::corrplot(cor(Wolves[,4:12]), method = "square" , order = "hclust", tl.col='black', tl.cex=.75) 

```

Por fim, considere o boxplot das variáveis separadas por grupo.

```{r boxplot}
plots <- list()
for (i in 1:ncol(Wolves)) {
  var_name = names(Wolves)[i]

  if (is.numeric(Wolves[[var_name]])) {
    label <- attr(Wolves[[var_name]], "label")
  
    p <- ggplot(data = Wolves, aes_string(x = "group", y = var_name)) +
      geom_boxplot() +
      labs(title = label, x = "", y = "") +
      theme_minimal()
    
    plots[[length(plots) + 1]] <- p
  }
}
library(gridExtra)
do.call("grid.arrange", c(plots, ncol = 3))
```

## Análise de discriminante

O primeiro passo para realizar a análise de discriminante é verificar a
normalidade dos dados.

```{r teste de normalidade}
N_W <- Wolves[,4:length(Wolves)]


MVN::mvn(data = N_W, mvnTest = "mardia", multivariatePlot = "qq") #Conjuntamente segue normalmultivariada, ou seja, os grupos seguem normal multivarida.

```

```{r}

X<-as.matrix(Wolves[,c(-1,-2,-3)])
X_d <- dist(X)
X <- vegan::betadisper(X_d,Wolves$group)
vegan::permutest(X) # Matriz de covariancias são homogeneas
plot(X)


Manova <- aov(x1+x2+x3+x4+x5+x6+x7+x8+x9 ~ group, data = Wolves)
summary(Manova) # As medias não são homogeneas

#Análise discriminante
Wolves_n <- Wolves[,c(1,4:12)]
spe.lda <- lda(group ~., data=Wolves_n)

round(predict(spe.lda)$posterior,2)

ta <- table(Wolves[,1],predict(spe.lda)$class)

diag(prop.table(ta,1))

caret::confusionMatrix(predict(spe.lda)$class, Wolves$group)
```

## K-means

```{r ncluster}
#### K-means ####
library(factoextra)

X = Wolves[,-c(1:3)] #Sem considera grupo -< mas deveriamos considerar sexo e loc??

X = as.matrix(X)

fviz_nbclust(X, kmeans, method = "wss")
```

Pelo gráfico parece razoável escolher 4 clusters

```{r clustering}

K = 4

km_res <- kmeans(X, centers = K)

# Plotar os clusters fornecidos pelo K-means
plot(X, col = km_res$cluster, pch = 16, main = "Clusters K-means", 
     xlab = "Palatal length", ylab = "postpalatal length")

# Plotar os centróides dos grupos
points(km_res$centers, col = 1:K, pch = 8, cex = 2)


```

## Agrupamento hierárquico

Agora, o objetivo será realizar um agrumento hierarquico nos dados. Para
isso, primeiro serão realizadas algumas mudanças na base de dados.

```{r}
##como numeric
Xh = Wolves[,-1]
Xh$location = ifelse(Xh$location == "rm", 1,0)
Xh$sex = ifelse(Xh$sex == "m", 1,0)

Xh = Xh |> 
  mutate(across(c(location,sex), as.numeric))

Xh = scale(Xh)
```

Veja que os dados foram padronizados, ... Para realizar o agrupamento,
primeiro é calculada a matriz de distâncias, depois prossegue-se com o
algoritmo de ligação.

```{r}
dist_matrix <- dist(Xh)

hc_complete <- hclust(dist_matrix, method = "complete")

plot(hc_complete, main = "Complete Linkage Hierarchical Clustering", sub = "", xlab = "")
```

Com os resultados obtidos, é então possível realizar o agrupamento. Para
isso, considere como critério a medida de dissimilaridade Sendo assim,
ficaremos com o total de 3 grupos distintos.

## Comparação do k-means e do agrupamento hierárquico

Para fazer a comparação, primeiro iremos atribuir as observações aos
seus grupos encontrados pelos algoritmos.

```{r}

# Plotar o gráfico de agrupamento usando fviz_cluster
fviz_cluster(km_res, data = X,
             ggtheme = theme_minimal(),
             main = "Agrupamento por K-means")

fviz_cluster(list(data = Xh, cluster = cutree(hc_complete, k = 3)),
             ggtheme = theme_minimal(),
             main = "Agrupamento hierárquico")

```

# Questão 3

```{r leitura3}
dados = read.table("https://raw.githubusercontent.com/Claudionor20/MultivariateAnalysis/main/bases/alimentos.txt", header = T)
row.names(dados)=dados$pais
head(dados)
```

## Hierarquia parcial

Em um primeiro momento, será de interesse construir um modelo
hierárquico utilizando apenas as variáveis leite e fruta/legumes.

```{r hir_leiteFL}
dados_LF = dplyr::select(dados, lech, fleg)
dados_LF = scale(dados_LF)
dist_matrix = dist(dados_LF)

hc_FL = hclust(dist_matrix, method = "complete")

plot(hc_FL, main = "Ligação completa usando Leite e Frutas/Legumes", sub = "", xlab = "")
```

## Hierarquia completa

É possível prosseguir com a análise considerando todas as variáveis.
Considere, então, o método de ligação completo.

```{r hier_ALL}
dados_All = dplyr::select(dados, -pais)
dados_All = scale(dados_All)
dist_matrix_All = dist(dados_All)

hc_All = hclust(dist_matrix_All, method = "complete")
plot(hc_All, main = "Ligação completa com todas as variáveis", sub = "", xlab = "")

```

## Hierarquica completa com average

Agora, o objetivo será realizar o agrupamento com o método de ligação
média, isto é, metodo $average$.

```{r hier_avg}
Xa = dplyr::select(dados, -pais)
Xa = scale(Xa)
dist_matrix_avg = dist(Xa)

hc_avg = hclust(dist_matrix_avg, method = "average")

plot(hc_avg, main = "Average ligação com todas as variáveis", sub = "", xlab = "")
```

## Cortando as árvores

Vemos métodos de ligações diferentes utilizando variáveis diferentes, a
fim de comparação, considere os agrupamentos utilizando a ligação
completa com números de cluster 2 e 3.

Primeiro, é realizado o corte no contexto das variáveis consumo de leite
e frutas/legumes.

```{r k23 leite}
plot(hc_FL, main = "Ligação completa usando Leite e Frutas/Legumes", sub = "", xlab = "")
abline(h = 2.5, col = "red", lty = 2) 
abline(h = 2.1, col = "blue", lty = 2) 
legend("topright", legend = c("2 grupos", "3 grupos"), col = c("red", "blue"), lty = c(2, 3), bty = "n")
```

Dessa forma, para 2 $clusters$ temos:

```{r}
plot(hc_FL, main = "Ligação completa usando Leite e Frutas/Legumes", sub = "", xlab = "")
rect.hclust(hc_FL, k = 2, border = 2:4)
```

Sendo assim, teriamos o primeiro $cluster$ com Hungria, Japão e México,
o segundo $cluster$ com Espanha, Reino Unido, Noruega, Países Baixos,
França e Estados Unidos.

Já para 3 $clusters$ temos:

```{r}
plot(hc_FL, main = "Ligação completa usando Leite e Frutas/Legumes", sub = "", xlab = "")
rect.hclust(hc_FL, k = 3, border = 2:5)
```

Sendo assim, teriamos o primeiro $cluster$ com Hungria, Japão e México,
o segundo $cluster$ com Espanha e o terceiro com Reino Unido, Noruega,
Países Baixos, França e Estados Unidos.

```{r cutTree complete}
#k=2
clustersFL_2 <- cutree(hc_FL, k = 2)
dados$clustersFL_2 <- clustersFL_2
#k = 3
clustersFL_3 <- cutree(hc_FL, k = 3)
dados$clustersFL_3 <- clustersFL_3

dados = dados |> dplyr::select(pais,clustersFL_2,clustersFL_3)

flextable(dados) %>%
  theme_vanilla() %>%
  autofit() %>%
  set_caption(caption = "Corte usando apenas Leites e legumes/frutas") %>%
  color(j = 1, color = "darkblue") |> 
  set_header_labels(
    pais = "País",
    clustersFL_2 = "2 clusters",
    clustersFL_3 = "3 clusters"
  ) %>%
  colformat_double(digits = 2)
```

Ainda, fazendo o corte pra todas as variáveis:

```{r k34 tudo}
plot(hc_All, main = "Ligação completa com todas as variáveis", sub = "", xlab = "")
abline(h = 7.65, col = "red", lty = 2) 
abline(h = 5, col = "blue", lty = 2) 
legend("topright", legend = c("2 grupos", "3 grupos"), col = c("red", "blue"), lty = c(2, 3), bty = "n")
```

Dessa forma, para 2 $clusters$ temos:

```{r}
plot(hc_All, main = "Ligação completa com todas as variáveis", sub = "", xlab = "")
rect.hclust(hc_All, k = 2, border = 2:4)
```

Sendo assim, teriamos o primeiro $cluster$ com Hungria, em quanto o
segundo é formado pelos demais países.

Já para 3 $clusters$ temos:

```{r}
plot(hc_All, main = "Ligação completa com todas as variáveis", sub = "", xlab = "")
rect.hclust(hc_FL, k = 3, border = 2:5)
```

Sendo assim, teriamos o primeiro $cluster$ com Hungria, já o segundo
$cluster$ com Espanha, Países Baixos, França e Estados Unidos, e o
terceiro com Reino Unido, Noruega, Japão e México.

Ainda,

```{r}
#k = 2
clustersAll_2 <- cutree(hc_All, k = 2)
dados2 = dados
dados2$clustersAll_2 <- clustersAll_2

#k = 3
clustersAll_3 <- cutree(hc_All, k = 3)
dados2$clustersAll_3 <- clustersAll_3

dados2 = dados2 |> dplyr::select(pais,clustersAll_2,clustersAll_3)

flextable(dados2) %>%
  theme_vanilla() %>%
  autofit() %>%
  set_caption(caption = "Corte usando todas as variáveis") %>%
  color(j = 1, color = "darkblue") |> 
  set_header_labels(
    pais = "País",
    clustersFL_2 = "2 clusters",
    clustersFL_3 = "3 clusters"
  ) %>%
  colformat_double(digits = 2)
```

## Visualização gráfico

```{r}

fviz_cluster(list(data = dados_LF, cluster = clustersFL_2), 
             geom = "point", 
             ellipse.type = "convex", 
             palette = "jco", 
             ggtheme = theme_minimal()) + 
  geom_text(aes(label = rownames(dados_LF)), vjust = -0.5, hjust = 0.5)+
  labs(title = "Leite e fruta/legumes")

fviz_cluster(list(data = dados_LF, cluster = clustersFL_3), 
             geom = "point", 
             ellipse.type = "convex", 
             palette = "jco", 
             ggtheme = theme_minimal()) + 
  geom_text(aes(label = rownames(dados_LF)), vjust = -0.5, hjust = 0.5)+
  labs(title = "Leite e fruta/legumes")


fviz_cluster(list(data = dados_All, cluster = clustersAll_2), 
             geom = "point", 
             ellipse.type = "convex", 
             palette = "jco", 
             ggtheme = theme_minimal()) + 
  geom_text(aes(label = rownames(dados_LF)), vjust = -0.5, hjust = 0.5)+
  labs(title = "Todas as variáveis")


fviz_cluster(list(data = dados_All, cluster = clustersAll_3), 
             geom = "point", 
             ellipse.type = "convex", 
             palette = "jco", 
             ggtheme = theme_minimal()) + 
  geom_text(aes(label = rownames(dados_LF)), vjust = -0.5, hjust = 0.5)+
  labs(title = "Todas as variáveis")

```

# Questão 4

### Bases

Considere as bases a serem utilizadas na análise

```{r bibliotecas4, warning=FALSE}
require(dplyr)
require(GGally)
library(ggplot2)
library(reshape2)
library(caret)
library(corrplot)
library(factoextra)
library(cluster)
library(FactoMineR)
library(CGPfunctions)

```

```{r basesIPS}
ips= read.csv(file = "https://raw.githubusercontent.com/Claudionor20/MultivariateAnalysis/main/bases/IPS.csv", sep = ';')

ips_anos = list(ips_2016 = dplyr::filter(ips, ano == 2016), 
                ips_2018 = dplyr::filter(ips, ano == 2018),
                ips_2020 = dplyr::filter(ips, ano == 2020), 
                ips_2022 = dplyr::filter(ips, ano == 2022))
```

## Análise Descritiva de Dados

### Média de IPS ao longo dos anos por região administrativa

```{r}
ips |>
  group_by(regiao_administrativa) %>%
  summarise(media_ips = mean(ips_geral)) %>%
  arrange(desc(media_ips)) %>%
  ggplot(aes(x = reorder(regiao_administrativa, media_ips), y = media_ips)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme_minimal() +
  coord_flip() +
  labs(title = "Média de IPS por Região Administrativa",
       x = "Região Administrativa",
       y = "Média de IPS")

```

### Evolução anual do IPS de cada regisão administrativa

```{r fig.width=15, fig.height=8}
ips |>
  ggplot(aes(x = factor(ano), y = ips_geral)) +
  geom_bar(stat = "identity", position = "dodge", aes(fill = regiao_administrativa), width = 0.7) +
  scale_fill_viridis_d() +  
  theme_minimal() +
  theme(
    text = element_text(size = 14),  
    axis.text.x = element_text(size = 12),  
    axis.text.y = element_text(size = 12),  
    legend.title = element_text(size = 12), 
    legend.text = element_text(size = 10),  
    panel.grid.major = element_line(color = "gray", linetype = "dotted"),  
    panel.grid.minor = element_blank()  
  ) +
  labs(
    title = "Evolução do IPS por Região Administrativa",
    x = "Ano",
    y = "IPS",
    fill = "Região Administrativa"
  ) +
  facet_wrap(~ regiao_administrativa, scales = "free_y", ncol = 6)  
```

### Boxplot dos indicadores de IPS por ano

```{r}
ips_geral <- ips|>
  dplyr::select(ano,ips_geral)

ips_geral|>
  ggplot(aes(x = as.factor(ano), y = ips_geral)) +
  geom_boxplot(aes(fill = "Ano"), color = "gray50", outlier.color = "red", outlier.shape = 16, outlier.size = 3) +
  scale_fill_manual(values = "#66C2A5") + 
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.x = element_blank(),  
    panel.grid.minor = element_blank(),  
    legend.position = "none"  
  ) +
  labs(
    title = "Distribuição do IPS por Ano",
    x = "Ano",
    y = "IPS"
  )
```

### Histogramas

```{r fig.width=12, fig.height=8}
data_long <- melt(ips, id.vars = c("ano", "regiao_administrativa"))


ggplot(data_long, aes(x = value)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  theme_minimal() +
  facet_wrap(~ variable, scales = "free_x") +
  labs(title = "Histogramas Dos Indicadores do IPS",
       x = "Valor",
       y = "Frequência")
```

## Análise PCA

### Componentes Principais e Municípios
##### Com base no gráfico de 2016 ,é possível perceber que o IPS é bastante influenciado pela primeira componente principal. Essa componente trata majoritariamente do Acesso a educação e Informação. Diante disso, conclui-se que regiões como Lago, Botafogo e Copacabana possuem um alto IPS devido, em grande parte, aos altos indices de acesso a educação e informação. Em contraste com isso, as regiões como Jacarezinho, Rocinha e Complexo do Alemão possuem um IPS mais baixo, em maioria, devido a falta desses recursos.

```{r}
# Remover colunas categóricas e escalar os dados
IPS_d <- scale(ips_anos$ips_2016[,-c(1,2,3)])
IPS_pca <- scale(ips_anos$ips_2016[,-c(1,2)])
rownames(IPS_d) <- ips_anos$ips_2016$regiao_administrativa
rownames(IPS_pca) <- ips_anos$ips_2016$regiao_administrativa

# Executar a PCA
pca_result <- PCA(IPS_pca, ncp = ncol(IPS_d), quanti.sup = c(1), graph = FALSE)
var_out <- get_pca_var(pca_result)
loadings <- var_out$coord
corelacao_pca <- var_out$cor
varia_pca <- row.names(corelacao_pca[abs(corelacao_pca[, "Dim.1"]) >= 0.8, ])

# Garantir que os nomes das linhas sejam consistentes para outros anos
rownames(ips_anos$ips_2018) <- ips_anos$ips_2016$regiao_administrativa
rownames(ips_anos$ips_2020) <- ips_anos$ips_2016$regiao_administrativa
rownames(ips_anos$ips_2022) <- ips_anos$ips_2016$regiao_administrativa


#fviz_eig(pca_result, addlabels = TRUE, ylim = c(0, 50),main = "") # Gráfico de Variabilidade

fviz_pca_biplot(pca_result,addlabels = TRUE)
```

### Agrupamento Hierárquico das Regiões Administrativas


```{r}
#####Agrupando utilizando todas as variáveis #####
scores_2016 <- as.data.frame(as.matrix(IPS_d) %*% as.matrix(loadings))

dist_ipsc = dist(scores_2016)

cluster_ips2 = hclust(dist_ipsc, method = "complete")

plot(cluster_ips2, main = "Modelo Hierárquico completo", xlab = "", ylab = "",sub = "", yaxt = "n", cex = 0.6)

# Adicionar retângulos ao redor dos clusters
rect.hclust(cluster_ips2, k = 4, border = 2:5) # Aqui, k define o número de clusters, ajuste conforme necessário
```

### Gráfico Média do IPS Geral por Cluster Hierárquico ao Decorrer dos Anos

```{r}
clusters_ips <- cutree(cluster_ips2, k = 4)


ips_cl = ips
ips_cl$cluster = rep(clusters_ips, times = length(unique(ips$ano)))

ips_cl |> 
  group_by(cluster,ano) |> 
  summarise(m_ipsgeral = round(mean(ips_geral),1)) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = m_ipsgeral,
                  Grouping = cluster) +
  labs(title = "Média do IPS Geral por Cluster", 
       subtitle = "Região administrativa")
```
###### Nas análises a seguir, as regiões administrativas Rocinha, Maré, Lagoa e Méier foram escolhidas para uma avaliação detalhada do ###### comportamento de seus indicadores ao longo dos anos.

### Comportamento dos Indicadores que mais Impactam o PC1 Positivamente na Rocinha, Maré, Lagoa e Méier

```{r}

ips_clv = ips_cl |>  dplyr::select(regiao_administrativa, ano, all_of(varia_pca), ips_geral, cluster)

a1 = ips_clv |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_vulnerabilidade_familiar,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_vulnerabilidade_familiar", 
       subtitle = "Região administrativa")

a2 = ips_clv |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_gravidez_adolescencia,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_gravidez_adolescencia", 
       subtitle = "Região administrativa")

a3 = ips_cl |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_adensamento_habitacional_excessivo,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_adensamento_habitacional_excessivo", 
       subtitle = "Região administrativa")

a4 = ips_cl |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_alfabetizacao,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_alfabetizacao", 
       subtitle = "Região administrativa")


gridExtra::grid.arrange(a1,a2,a3,a4)
```

### Comportamento dos Indicadores que mais Impactam o PC1 Negativamente na Rocinha, Maré, Lagoa e Méier

```{r}
ips_clv = ips_cl |>  dplyr::select(regiao_administrativa, ano, all_of(varia_pca), ips_geral, cluster)


g1 = ips_clv |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_frequencia_ensino_superior,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_frequencia_ensino_superior", 
       subtitle = "Região administrativa")

g2 = ips_clv |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_acesso_telefone_celular_fixo,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_acesso_telefone_celular_fixo", 
       subtitle = "Região administrativa")

g3 = ips_cl |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_pessoas_ensino_superior,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_pessoas_ensino_superior", 
       subtitle = "Região administrativa")

g4 = ips_cl |> 
  filter(regiao_administrativa %in% c("Rocinha", "Lagoa", "Maré", "Méier")) |> 
  mutate(ano = factor(ano)) |> 
  newggslopegraph(Times = ano,
                  Measurement = prop_acesso_internet,
                  Grouping = regiao_administrativa) +
  labs(title = "prop_acesso_internet", 
       subtitle = "Região administrativa")

gridExtra::grid.arrange(g1,g2,g3,g4)
```
